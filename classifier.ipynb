{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-16T23:49:38.678987Z","iopub.execute_input":"2023-04-16T23:49:38.679379Z","iopub.status.idle":"2023-04-16T23:49:38.723463Z","shell.execute_reply.started":"2023-04-16T23:49:38.679343Z","shell.execute_reply":"2023-04-16T23:49:38.722177Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/political-social-media-posts/political_social_media.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#read in the data and give labels 1 or 0 for partisan or neutral\ndata = pd.read_csv('/kaggle/input/political-social-media-posts/political_social_media.csv', usecols=[7,20], names=['bias','text'], encoding='ISO-8859-1')\ndata.loc[data['bias'] == 'neutral', 'bias'] = 1\ndata.loc[data['bias'] == 'partisan', 'bias'] = 0\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:49:38.725495Z","iopub.execute_input":"2023-04-16T23:49:38.725877Z","iopub.status.idle":"2023-04-16T23:49:38.885594Z","shell.execute_reply.started":"2023-04-16T23:49:38.725842Z","shell.execute_reply":"2023-04-16T23:49:38.884077Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   bias                                               text\n0  bias                                               text\n1     0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...\n2     0  VIDEO - #Obamacare:  Full of Higher Costs and ...\n3     1  Please join me today in remembering our fallen...\n4     1  RT @SenatorLeahy: 1st step toward Senate debat...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bias</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bias</td>\n      <td>text</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Please join me today in remembering our fallen...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\n#preprocess the twitter data and remove all unecessary characters\ndef preprocess_text(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Remove mentions\n    text = re.sub(r'@\\w+', '', text)\n    \n    # Remove hashtags\n    text = re.sub(r'#\\w+', '', text)\n    \n    # Remove special characters and digits\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    \n    # Convert to lowercase\n    text = text.lower()\n    \n    return text\n\n# Apply the preprocessing function to the 'text' column\ndata['cleaned_text'] = data['text'].apply(preprocess_text)\n\n#turn the cleaned text into an array\ntext = data['cleaned_text'].to_numpy()\nX = text[1:]\n\n#do the same for the y values (I had to use .values to get it to work for some reason)\ny = data['bias'].values\ny = y[1:]\nprint(X)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:49:42.017941Z","iopub.execute_input":"2023-04-16T23:49:42.018354Z","iopub.status.idle":"2023-04-16T23:49:42.089212Z","shell.execute_reply.started":"2023-04-16T23:49:42.018318Z","shell.execute_reply":"2023-04-16T23:49:42.086154Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['rt  rep trey radel r  slams   '\n 'video    full of higher costs and broken promises '\n 'please join me today in remembering our fallen heroes and honoring the men and women currently in military service for their sacrifices'\n ...\n 'taken from posted wokv interview   congressman yoho says the decision to release the detainees in exchange for a soldier the us military says walked away from his post in afghanistan was poor leadership he also believes it sets a bad precedent  our enemies dont fear or respect us and i think respect is the most important part here   '\n 'join me next week for a town hall in ocala ill be there to answer any questions you might have '\n 'foreign affairs committee hearing on syria i remain opposed to military intervention but am always willing to hear different points of view this hearing sheds some light on the refugee situation check it out here']\n[0 0 1 ... 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into train, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Create the vectorizer\ncv = CountVectorizer()\n\n# Fit the vectorizer on the training data\nX_train_cv = cv.fit_transform(X_train)\n\n# Transform the validation and test data using the vectorizer\nX_val_cv = cv.transform(X_val)\nX_test_cv = cv.transform(X_test)\n\ny_train = np.array(y_train, dtype=int)\ny_test = np.array(y_test, dtype=int)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:49:49.541573Z","iopub.execute_input":"2023-04-16T23:49:49.542029Z","iopub.status.idle":"2023-04-16T23:49:50.277146Z","shell.execute_reply.started":"2023-04-16T23:49:49.541992Z","shell.execute_reply":"2023-04-16T23:49:50.275786Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n# Instantiate the SVM classifier\nsvm_classifier = SVC()\n\n# Train the classifier\nsvm_classifier.fit(X_train_cv, y_train)\n\n# Make predictions on the test set\ny_test_pred_svm = svm_classifier.predict(X_test_cv)\n\n# Calculate and report the accuracy\nsvm_accuracy = accuracy_score(y_test, y_test_pred_svm)\nprint(f\"SVM accuracy: {svm_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:51:55.801205Z","iopub.execute_input":"2023-04-16T23:51:55.801841Z","iopub.status.idle":"2023-04-16T23:51:59.399852Z","shell.execute_reply.started":"2023-04-16T23:51:55.801791Z","shell.execute_reply":"2023-04-16T23:51:59.398595Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"SVM accuracy: 0.7640\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Instantiate the Naive Bayes classifier\nnb_classifier = MultinomialNB()\n\n# Train the classifier\nnb_classifier.fit(X_train_cv, y_train)\n\n# Make predictions on the test set\ny_test_pred_nb = nb_classifier.predict(X_test_cv)\n\n# Calculate and report the accuracy\nnb_accuracy = accuracy_score(y_test, y_test_pred_nb)\nprint(f\"Naive Bayes accuracy: {nb_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:52:02.596854Z","iopub.execute_input":"2023-04-16T23:52:02.597241Z","iopub.status.idle":"2023-04-16T23:52:02.618430Z","shell.execute_reply.started":"2023-04-16T23:52:02.597208Z","shell.execute_reply":"2023-04-16T23:52:02.617035Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Naive Bayes accuracy: 0.7520\n","output_type":"stream"}]},{"cell_type":"code","source":"#I just did this to take a look at some extra metrics, it looks like SVM is the best\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef print_metrics(y_true, y_pred, classifier_name):\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    \n    print(f\"{classifier_name} Precision: {precision:.4f}\")\n    print(f\"{classifier_name} Recall: {recall:.4f}\")\n    print(f\"{classifier_name} F1-score: {f1:.4f}\")\n    print()\n\n# SVM Metrics\nprint_metrics(y_test, y_test_pred_svm, \"SVM\")\n\n# Naive Bayes Metrics\nprint_metrics(y_test, y_test_pred_nb, \"Naive Bayes\")","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:52:05.310925Z","iopub.execute_input":"2023-04-16T23:52:05.312227Z","iopub.status.idle":"2023-04-16T23:52:05.327138Z","shell.execute_reply.started":"2023-04-16T23:52:05.312167Z","shell.execute_reply":"2023-04-16T23:52:05.325801Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"SVM Precision: 0.7695\nSVM Recall: 0.9842\nSVM F1-score: 0.8637\n\nNaive Bayes Precision: 0.8616\nNaive Bayes Recall: 0.8026\nNaive Bayes F1-score: 0.8311\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SVM (Support Vector Machine) - sklearn.svm.SVC**\nHyperparameters:\nC: Regularization parameter, default=1.0\nkernel: Kernel type, default='rbf'\ngamma: Kernel coefficient, default='scale'\n\n**Naive Bayes - sklearn.naive_bayes.MultinomialNB**\nHyperparameters:\nalpha: Additive (Laplace/Lidstone) smoothing parameter, default=1.0\nfit_prior: Whether to learn class prior probabilities, default=True\nclass_prior: Prior probabilities of the classes, default=None","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\n# Define the hyperparameter grid\nparam_grid = {'C': [0.1, 1, 10],\n              'kernel': ['linear', 'rbf'],\n              'gamma': ['scale', 'auto']}\n\n# Initialize the classifier\nsvm = SVC()\n\n# Create a GridSearchCV object\ngrid_search = GridSearchCV(svm, param_grid, scoring='accuracy', cv=5, verbose=1)\n\n# Fit the GridSearchCV object to the training data\ngrid_search.fit(X_train_cv, y_train)\n\n# Get the best combination of hyperparameters\nbest_params = grid_search.best_params_\nprint(\"Best hyperparameters:\", best_params)\n\n# Get the prediction accuracy on the validation set\nbest_val_accuracy = grid_search.best_score_\nprint(\"Best validation accuracy:\", best_val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:52:09.169954Z","iopub.execute_input":"2023-04-16T23:52:09.171472Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the hyperparameters and their ranges\nhyperparameters_nb = {\n    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n    'fit_prior': [True, False]\n}\n\n# Instantiate a Multinomial Naive Bayes classifier\nnb = MultinomialNB()\n\n# Create a GridSearchCV object and fit it to the training data\nnb_grid = GridSearchCV(nb, hyperparameters_nb, cv=5, scoring='accuracy')\nnb_grid.fit(X_train_cv, y_train)\n\n# Print the best hyperparameters\nprint(\"Best hyperparameters for Naive Bayes:\", nb_grid.best_params_)\n\n# Print the accuracy score on the test set with the best hyperparameters\nnb_best = nb_grid.best_estimator_\nnb_best_pred = nb_best.predict(X_test_cv)\nnb_best_acc = accuracy_score(y_test, nb_best_pred)\nprint(f\"Accuracy on the test set with best hyperparameters for Naive Bayes: {nb_best_acc:.4f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Calculate ROC curve and AUC for SVM\nsvm_fpr, svm_tpr, _ = roc_curve(y_test, y_test_pred_svm)\nsvm_auc = auc(svm_fpr, svm_tpr)\n\n# Calculate ROC curve and AUC for Naive Bayes\nnb_fpr, nb_tpr, _ = roc_curve(y_test, y_test_pred_nb)\nnb_auc = auc(nb_fpr, nb_tpr)\n\n# Plot ROC curves\nplt.plot(svm_fpr, svm_tpr, color='darkorange', lw=2, label='SVM (AUC = %0.2f)' % svm_auc)\nplt.plot(nb_fpr, nb_tpr, color='navy', lw=2, label='Naive Bayes (AUC = %0.2f)' % nb_auc)\nplt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}